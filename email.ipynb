{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18ef38d4",
   "metadata": {},
   "source": [
    "read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8bdf1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from urllib.parse import urlparse\n",
    "data_list = []\n",
    "for home, dirs, files in os.walk(\"数据集/monkey数据集/数据集/\"):\n",
    "    for filename in files:\n",
    "        fullname = os.path.join(home, filename)\n",
    "        file = open(fullname, \"r\")\n",
    "        try:\n",
    "            content = file.read()\n",
    "            file.close()\n",
    "            data_list.append((fullname, content))\n",
    "            file.close()\n",
    "        except:\n",
    "            file.close()\n",
    "            pass\n",
    "data = pd.DataFrame(data_list, columns=['path', 'text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc44d99",
   "metadata": {},
   "source": [
    "read index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9d6d9e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '数据集/monkey数据集/数据集说明/index'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-2-a9a8ff72fed5>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mindex\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"数据集/monkey数据集/数据集说明/index\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mheader\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mindex\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;34m\"index\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mindex\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'path'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mindex\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'index'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mlambda\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;34m\"数据集/monkey数据集/数据集\"\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"data\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mindex\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'nor_phish'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mindex\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'index'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mlambda\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\" \"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mindex\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'label'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mindex\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'nor_phish'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mlambda\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;36m1\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mx\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"phishing\"\u001B[0m \u001B[1;32melse\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    608\u001B[0m     \u001B[0mkwds\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkwds_defaults\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    609\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 610\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    611\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    612\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    460\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    461\u001B[0m     \u001B[1;31m# Create the parser.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 462\u001B[1;33m     \u001B[0mparser\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    463\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    464\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m    817\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"has_index_names\"\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"has_index_names\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    818\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 819\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    820\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    821\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[1;34m(self, engine)\u001B[0m\n\u001B[0;32m   1048\u001B[0m             )\n\u001B[0;32m   1049\u001B[0m         \u001B[1;31m# error: Too many arguments for \"ParserBase\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1050\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mmapping\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# type: ignore[call-arg]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1051\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1052\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_failover_to_python\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, src, **kwds)\u001B[0m\n\u001B[0;32m   1865\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1866\u001B[0m         \u001B[1;31m# open handles\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1867\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_open_handles\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1868\u001B[0m         \u001B[1;32massert\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhandles\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1869\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mkey\u001B[0m \u001B[1;32min\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;34m\"storage_options\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"encoding\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"memory_map\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"compression\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36m_open_handles\u001B[1;34m(self, src, kwds)\u001B[0m\n\u001B[0;32m   1360\u001B[0m         \u001B[0mLet\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mreaders\u001B[0m \u001B[0mopen\u001B[0m \u001B[0mIOHanldes\u001B[0m \u001B[0mafter\u001B[0m \u001B[0mthey\u001B[0m \u001B[0mare\u001B[0m \u001B[0mdone\u001B[0m \u001B[1;32mwith\u001B[0m \u001B[0mtheir\u001B[0m \u001B[0mpotential\u001B[0m \u001B[0mraises\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1361\u001B[0m         \"\"\"\n\u001B[1;32m-> 1362\u001B[1;33m         self.handles = get_handle(\n\u001B[0m\u001B[0;32m   1363\u001B[0m             \u001B[0msrc\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1364\u001B[0m             \u001B[1;34m\"r\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\anaconda\\lib\\site-packages\\pandas\\io\\common.py\u001B[0m in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    640\u001B[0m                 \u001B[0merrors\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"replace\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    641\u001B[0m             \u001B[1;31m# Encoding\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 642\u001B[1;33m             handle = open(\n\u001B[0m\u001B[0;32m    643\u001B[0m                 \u001B[0mhandle\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    644\u001B[0m                 \u001B[0mioargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '数据集/monkey数据集/数据集说明/index'"
     ]
    }
   ],
   "source": [
    "index = pd.read_csv(\"数据集/monkey数据集/数据集说明/index\", header=None)\n",
    "index.columns = [\"index\"]\n",
    "index['path'] = index['index'].apply(lambda x: \"数据集/monkey数据集/数据集\" + x.split(\"data\")[1])\n",
    "index['nor_phish'] = index['index'].apply(lambda x: x.split(\" \")[0])\n",
    "index['label'] = index['nor_phish'].apply(lambda x: 1 if x == \"phishing\" else 0)\n",
    "# index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a55ae6e",
   "metadata": {},
   "source": [
    "merge data and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b08fb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(data, index, on=\"path\", how=\"inner\").iloc[:, [1, 4]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f75b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93faed03",
   "metadata": {},
   "source": [
    "extract body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f169237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_body(text):\n",
    "    import email.parser\n",
    "    import email\n",
    "    from email.parser import Parser\n",
    "    body = ''\n",
    "    subject = ''\n",
    "    date = ''\n",
    "    parser = Parser()\n",
    "    msg = email.message_from_string(text)\n",
    "    email = parser.parsestr(text)\n",
    "    if msg.is_multipart():\n",
    "        for payload in msg.get_payload():\n",
    "            body += str(payload)\n",
    "        try:\n",
    "            for sub in msg.get('subject'):\n",
    "                subject += str(sub)\n",
    "        except:\n",
    "            subject = ''\n",
    "    else:\n",
    "        body = msg.get_payload()\n",
    "        try:\n",
    "            subject = msg.get(\"subject\")\n",
    "        except:\n",
    "            subject = ''\n",
    "        date = msg.get(\"Date\")\n",
    "    return body, subject, date\n",
    "data['body'] = data['text'].apply(lambda x: extract_body(x)[0])\n",
    "data['subject'] = data['text'].apply(lambda x: extract_body(x)[1])\n",
    "data['Date'] = data['text'].apply(lambda x: extract_body(x)[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15780517",
   "metadata": {},
   "source": [
    "extract url from body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10a92c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urlextract import URLExtract\n",
    "extractor = URLExtract()\n",
    "data['urls'] = data['body'].apply(lambda x:list(set(extractor.find_urls(x))))\n",
    "# 判断发件时间是否为非工作日\n",
    "def judge_email_time(x):\n",
    "    if x:\n",
    "        if \"Sat\" in x or \"Sun\" in x:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0\n",
    "data['date_work'] = data['Date'].apply(judge_email_time)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13911bba",
   "metadata": {},
   "source": [
    "feature engineering-url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c367593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. count of dot\n",
    "from collections import Counter\n",
    "def url_to_domain(url):\n",
    "\to = urlparse(url)\n",
    "\tdomain = o.hostname\n",
    "\treturn domain\n",
    "data['dot'] = data['urls'].apply(lambda xs: sum([Counter(url_to_domain(x))['.'] for x in xs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcf1a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 是否含有端口号\n",
    "from urllib.parse import urlparse\n",
    "def ifcontainport(urls):\n",
    "    count = 0\n",
    "    for url in urls:\n",
    "        if urlparse(url).port:\n",
    "            count += 1\n",
    "    if count > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "data['port'] = data['urls'].apply(lambda xs: 1 if list(set([urlparse(x).port for x in xs]))!=[None] and len(xs)>0 else 0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c77e4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 含有端口号的url个数\n",
    "from urllib.parse import urlparse\n",
    "def count_urls_contain_post(urls):\n",
    "    count = 0\n",
    "    for url in urls:\n",
    "        if urlparse(url).port:\n",
    "            count += 1\n",
    "    return count\n",
    "    \n",
    "data['port1'] = data['urls'].apply(lambda x: count_urls_contain_post(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78ef594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. 包含ip的url个数\n",
    "import re\n",
    "def containipinlink(urls):\n",
    "    pattern = re.compile(r'(\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})')\n",
    "    count = 0\n",
    "    for url in urls:\n",
    "        try:\n",
    "            if pattern.search(url)[0]:\n",
    "                count += 1\n",
    "            else:\n",
    "                pass\n",
    "        except:\n",
    "            pass\n",
    "    return count\n",
    "data['ip'] = data['urls'].apply(lambda x: containipinlink(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e89a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. url 使用ip地址\n",
    "data['ip1'] = data['ip'].apply(lambda x: 1 if x>0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e4fa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. 连续使用域名数量\n",
    "data['domain_count'] = data['urls'].apply(lambda xs: len(set([url_to_domain(x) for x in xs])))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 11.链接数量\n",
    "data['urls_count'] = data['urls'].apply(lambda xs: len(xs))\n",
    "# 13.14.click here link\n",
    "data['click'] = data['urls'].apply(lambda x: 1 if 'click' in \",\".join(x).lower() else 0)\n",
    "data['here'] = data['urls'].apply(lambda x: 1 if 'here' in \",\".join(x).lower() else 0)\n",
    "data['link'] = data['urls'].apply(lambda x: 1 if 'link' in \",\".join(x).lower() else 0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "d36f2c41",
   "metadata": {},
   "source": [
    "feature engineering-body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edbc423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.suspension\n",
    "data['suspension'] = data['body'].apply(lambda x: 1 if \"suspension\" in x.lower() else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d2812a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.dear\n",
    "data['dear'] = data['body'].apply(lambda x: 1 if \"dear\" in x.lower() else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be0d906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. verify your account\n",
    "data['verifyyouraccount'] = data['body'].apply(lambda x: 1 if \"verify your account\" in x.lower() else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd436dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. HTML\n",
    "data['html'] = data['body'].apply(lambda x: 1 if \"html\" in x.lower() else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4a046f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 邮件正文丰富度 = 词的数量/字符的数量。\n",
    "data['w_count'] = data['body'].apply(lambda x: len(x.split(\" \")))\n",
    "data['str_count'] = data['body'].apply(lambda x: len(x))\n",
    "data['body_richness'] = round(data['w_count'] / data['str_count'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8595177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.account\n",
    "data['account_count'] = data['body'].apply(lambda x: Counter(x.split(\" \"))['account'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9c34eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. suspended\n",
    "data['suspended_count'] = data['body'].apply(lambda x: Counter(x.split(\" \"))['suspended'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d54bb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. 不重复单词个数\n",
    "data['word_count'] = data['body'].apply(lambda x: len(set(x.split(\" \"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a6d7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特殊字符\n",
    "# @：在电子邮件地址中使用，用于分隔用户名和域名。\n",
    "data['@'] = data['body'].apply(lambda x: 1 if \"@\" in x.lower() else 0)\n",
    "# !：用于增加紧迫感或强调重要性。\n",
    "data['!'] = data['body'].apply(lambda x: 1 if \"!\" in x.lower() else 0)\n",
    "# # ：用于标记话题或关键字。\n",
    "data['#'] = data['body'].apply(lambda x: 1 if \"#\" in x.lower() else 0)\n",
    "# %：用于表示折扣或优惠。\n",
    "data['%'] = data['body'].apply(lambda x: 1 if \"%\" in x.lower() else 0)\n",
    "# &：用于连接两个词或短语。\n",
    "data['&'] = data['body'].apply(lambda x: 1 if \"&\" in x.lower() else 0)\n",
    "# +：用于创建假电子邮件地址。\n",
    "data['+'] = data['body'].apply(lambda x: 1 if \"+\" in x.lower() else 0)\n",
    "# -：用于创建假网站地址或分隔单词。\n",
    "data['-'] = data['body'].apply(lambda x: 1 if \"-\" in x.lower() else 0)\n",
    "# _：用于创建假电子邮件地址。\n",
    "data['_'] = data['body'].apply(lambda x: 1 if \"_\" in x.lower() else 0)\n",
    "# $：用于表示货币或价格。\n",
    "data['$'] = data['body'].apply(lambda x: 1 if \"$\" in x.lower() else 0)\n",
    "# *：用于强调或突出显示重要部分。\n",
    "data['*'] = data['body'].apply(lambda x: 1 if \"*\" in x.lower() else 0)\n",
    "# /：用于创建假网站地址。\n",
    "data['/'] = data['body'].apply(lambda x: 1 if \"/\" in x.lower() else 0)\n",
    "# \\：用于混淆网址或文件路径\n",
    "data['\\\\'] = data['body'].apply(lambda x: 1 if \"\\\\\" in x.lower() else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2933c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 钓鱼邮件中敏感词\n",
    "data['contain_account'] = data['body'].apply(lambda x: 1 if \"account\" in x.lower() else 0)\n",
    "data['contain_password'] = data['body'].apply(lambda x: 1 if \"password\" in x.lower() else 0)\n",
    "data['contain_verify'] = data['body'].apply(lambda x: 1 if \"verify\" in x.lower() else 0)\n",
    "data['contain_reward'] = data['body'].apply(lambda x: 1 if \"reward\" in x.lower() else 0)\n",
    "data['contain_confidentiality'] = data['body'].apply(lambda x: 1 if \"confidentiality\" in x.lower() else 0)\n",
    "data['contain_cancel'] = data['body'].apply(lambda x: 1 if \"cancel\" in x.lower() else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072eeab3",
   "metadata": {},
   "source": [
    "feature engineering-subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229ce582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.bank\n",
    "data['bank'] = data['subject'].apply(lambda x: 1 if x and 'bank' in x.lower() else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c86147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. FW\n",
    "data['fw'] = data['subject'].apply(lambda x: 1 if x and 'FW' in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd990624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. re\n",
    "data['re'] = data['subject'].apply(lambda x: 1 if x and 're:' in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eafe8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. verify\n",
    "data['verify'] = data['subject'].apply(lambda x: 1 if x and 'verify' in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcb0595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.word count\n",
    "data['subject_word_count'] = data['subject'].apply(lambda x: len(str(x).split(\" \")) if x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dad5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.str count\n",
    "data['subject_str_count'] = data['subject'].apply(lambda x: len(str(x)) if x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765e0c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# richness\n",
    "data['subject_richness'] = round(data['subject_word_count'] / data['subject_str_count'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3cd93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 是否包含大写字母\n",
    "data['upper'] = data['subject'].apply(lambda x: 0 if x and x.islower() else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae66b620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = data.fillna(0)\n",
    "data = data.replace([np.inf, -np.inf], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4950e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339db4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a2d54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(np.isnan(data.iloc[:, 6:]).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2294840",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.iloc[:, 6:]\n",
    "labels = data.iloc[:, [1]]\n",
    "for i in list(features.columns):\n",
    "   # 获取各个指标的最大值和最小值\n",
    "    Max = np.max(features[i])\n",
    "    Min = np.min(features[i])\n",
    "    features[i] = (features[i] - Min)/(Max - Min)\n",
    "features = features.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8063fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(labels).groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a385185",
   "metadata": {},
   "source": [
    "split train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3644cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data, train_label, test_label = train_test_split(features, labels, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c42228",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa22319d",
   "metadata": {},
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d286a108",
   "metadata": {},
   "source": [
    "RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2386a719",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(random_state=0)\n",
    "rfc = rfc.fit(train_data, train_label)\n",
    "predict = rfc.predict(test_data)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_label, predict))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "c_m = confusion_matrix(test_label, predict)\n",
    "print(c_m)\n",
    "import seaborn as sns\n",
    "sns.heatmap(c_m)\n",
    "rfc.predict_proba(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a038b0c1",
   "metadata": {},
   "source": [
    "decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7663813",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(criterion='gini', splitter='best',max_depth=32,min_samples_split=2)\n",
    "dt = dt.fit(train_data, train_label)\n",
    "predict = dt.predict(test_data)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_label, predict))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "c_m = confusion_matrix(test_label, predict)\n",
    "print(c_m)\n",
    "import seaborn as sns\n",
    "sns.heatmap(c_m)\n",
    "dt.predict_proba(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b6b7bc",
   "metadata": {},
   "source": [
    "朴素贝叶斯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c2ba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb = gnb.fit(train_data, train_label)\n",
    "predict = gnb.predict(test_data)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_label, predict))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "c_m = confusion_matrix(test_label, predict)\n",
    "print(c_m)\n",
    "import seaborn as sns\n",
    "sns.heatmap(c_m)\n",
    "gnb.predict_proba(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f7b43f",
   "metadata": {},
   "source": [
    "神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1143f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5,2), random_state=1)  # 神经网络输入为2，第一隐藏层神经元个数为5，第二隐藏层神经元个数为2，输出结果为2分类。\n",
    "clf = clf.fit(train_data, train_label)\n",
    "predict = clf.predict(test_data)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_label, predict))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "c_m = confusion_matrix(test_label, predict)\n",
    "print(c_m)\n",
    "import seaborn as sns\n",
    "sns.heatmap(c_m)\n",
    "clf.predict_proba(test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1853e85d",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352b21f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "svc = svm.SVC(kernel=\"rbf\", C=1, probability=True)\n",
    "svc = svc.fit(train_data, train_label)\n",
    "predict = svc.predict(test_data)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_label, predict))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "c_m = confusion_matrix(test_label, predict)\n",
    "print(c_m)\n",
    "import seaborn as sns\n",
    "sns.heatmap(c_m)\n",
    "svc.predict_proba(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5c4f8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40006333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3b2c91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6060a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
